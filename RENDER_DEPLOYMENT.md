# Render Deployment Guide

## Quick Start

### 1. Prerequisites
- A Render account (https://render.com)
- Your code pushed to a Git repository (GitHub, GitLab, or Bitbucket)
- A Groq API key (https://console.groq.com/)

### 2. Deploy to Render

#### Option A: Using render.yaml (Recommended)
1. Go to https://dashboard.render.com/
2. Click "New" → "Blueprint"
3. Connect your Git repository
4. Render will automatically detect `render.yaml` and configure the service
5. Set the `GROQ_API_KEY` environment variable in the Render dashboard

#### Option B: Manual Setup
1. Go to https://dashboard.render.com/
2. Click "New" → "Web Service"
3. Connect your Git repository
4. Configure the following settings:

**Build Settings:**
- **Name:** ai-study-tutor
- **Runtime:** Python 3
- **Build Command:** `pip install --upgrade pip && pip install -r requirements.txt && python manage.py collectstatic --no-input && python manage.py migrate`
- **Start Command:** `gunicorn backend.wsgi:application --bind 0.0.0.0:$PORT --workers 2 --timeout 120`

**Environment Variables:**
Add these in the Render dashboard under "Environment":
- `DJANGO_SECRET_KEY` - Click "Generate" to auto-generate
- `GROQ_API_KEY` - Your Groq API key
- `DJANGO_SETTINGS_MODULE` - Set to `backend.settings`
- `PYTHON_VERSION` - Set to `3.11.7` (optional)

**Disk:**
- Click "Add Disk"
- **Name:** ai-study-tutor-data
- **Mount Path:** /opt/render/project/src/data
- **Size:** 1 GB (free tier)

### 3. Post-Deployment

After deployment:
1. Wait for the build to complete (first deployment takes 5-10 minutes due to ML model downloads)
2. Your app will be available at: `https://your-app-name.onrender.com`
3. Test the health endpoint: `https://your-app-name.onrender.com/healthz`
4. Access the chat interface: `https://your-app-name.onrender.com/static/chat.html`

## Configuration Details

### Environment Variables

**Required:**
- `DJANGO_SECRET_KEY` - Django secret key (auto-generated by Render)
- `GROQ_API_KEY` - Your Groq API key for AI features

**Optional:**
- `DEBUG` - Set to `True` for debugging (default: `False` in production)
- `RENDER_EXTERNAL_HOSTNAME` - Auto-set by Render

### Disk Storage

The persistent disk is mounted at `/opt/render/project/src/data` and stores:
- SQLite database (`db.sqlite3`)
- Uploaded documents (`data/uploads/`)
- Generated audio files (`data/audio/`)
- FAISS vector index (`data/index/`)

### Static Files

Static files are handled by WhiteNoise and collected to `/staticfiles/` during build.

## Troubleshooting

### Worker Timeout on Startup
If you see `WORKER TIMEOUT` errors:
- This is fixed in the latest config with `--timeout 300 --preload`
- The app lazy-loads ML models to avoid blocking worker startup
- First request may take 10-20 seconds to load models

### Python Version Mismatch (Python 3.13 errors)
If you see Python 3.13 in logs instead of 3.11:
- Ensure `PYTHON_VERSION=3.11.9` is set in environment variables
- Check `runtime.txt` contains `python-3.11.9`
- Python 3.13 has compatibility issues with some ML libraries

### Build Fails: "No module named 'sentence_transformers'"
- Ensure `sentence-transformers>=2.2.0` is in `requirements.txt`
- Check build logs for memory issues (ML models are large)

### App Crashes: "Port already in use"
- Ensure start command uses `$PORT` variable: `--bind 0.0.0.0:$PORT`
- Don't hardcode port 10000

### Static Files Not Loading
- Verify `python manage.py collectstatic --no-input` runs in build command
- Check that `whitenoise` is in `requirements.txt` and middleware
- Ensure `STATIC_ROOT = BASE_DIR / "staticfiles"` in settings.py

### Database Errors
- The disk must be properly mounted at `/opt/render/project/src/data`
- Check disk configuration in Render dashboard
- For data persistence, never delete the disk

### Slow First Request (Cold Start)
- Free tier services spin down after inactivity
- First request after spin-down takes 30-60 seconds
- Consider upgrading to paid tier for always-on service

### ML Model Download Takes Too Long
- First deployment downloads sentence-transformers model (~500MB)
- This is normal and only happens once
- Subsequent deploys use cached dependencies

## Monitoring

### Logs
View real-time logs in Render dashboard:
- Go to your service
- Click "Logs" tab
- Filter by log level (INFO, ERROR, etc.)

### Health Check
Render automatically pings `/healthz` endpoint to verify service health.

### Metrics
Free tier includes basic metrics:
- CPU usage
- Memory usage
- Request count
- Response times

## Scaling

### Free Tier Limitations
- 750 hours/month (shared across all services)
- Service spins down after 15 minutes of inactivity
- Limited memory and CPU

### Upgrading
To handle more traffic:
1. Upgrade to a paid plan ($7/month+)
2. Services stay always-on
3. More CPU and memory
4. Custom domains included

## Security Notes

1. **Never commit secrets** - Use environment variables
2. **Set DEBUG=False** in production (default in this config)
3. **ALLOWED_HOSTS** is auto-configured for Render hostname
4. **CSRF protection** is enabled by default
5. **SECRET_KEY** is generated securely by Render

## Support

If issues persist:
1. Check Render status page: https://status.render.com/
2. Review Render docs: https://render.com/docs
3. Check application logs in Render dashboard
4. Verify all environment variables are set correctly
5. Ensure disk is properly mounted

## Additional Resources

- Render Python Docs: https://render.com/docs/deploy-django
- Django Deployment Checklist: https://docs.djangoproject.com/en/stable/howto/deployment/checklist/
- Gunicorn Configuration: https://docs.gunicorn.org/en/stable/settings.html
